[[addrman]]
== ConnMan

`CConnman` class was created in the https://github.com/bitcoin/bitcoin/pull/8085[PR #8085] to to encapsulate P2P connections. Today, this class manages network layer logic.

It creates sockets for listening for incoming connections and binds them to addresses and ports. It loads the `peer.dat` file to connect to addresses previously seen or already connected to. It also loads the `anchors.dat` to establish block-only connections. It starts the network threads. It handles the interruption of the network and the node shutdown.

This text describes the Network Layer and and how Connman works.

The commit https://github.com/bitcoin/bitcoin/commit/c7dd9ff71b9c2e62fa7ecfb37ee7a5841ad67ecc[c7dd9ff71b] can be used as a reference to the https://github.com/bitcoin/bitcoin/tree/c7dd9ff71b9c2e62fa7ecfb37ee7a5841ad67ecc[project's codebase] at the time of writing.

 git clone https://github.com/bitcoin/bitcoin.git
 cd bitcoin
 git checkout -b text_branch c7dd9ff71b
                             
=== Starting The Node

The `CConnman` and all the network processes are started in `AppInitMain(...)`, which is basically the main function of the application. When the node shuts down, connections are securely closed by `CConnman`.

[source,c++]  
----
bool AppInitMain(NodeContext& node, interfaces::BlockAndHeaderTipInfo* tip_info)
{
    // ...
    assert(!node.connman);
    node.connman = std::make_unique<CConnman>(GetRand(std::numeric_limits<uint64_t>::max()), GetRand(std::numeric_limits<uint64_t>::max()), *node.addrman, args.GetBoolArg("-networkactive", true));
    // ...
    if (!node.connman->Start(*node.scheduler, connOptions)) {
        return false;
    }
    // ...
}

void Interrupt(NodeContext& node)
{
    // ...
    if (node.connman)
        node.connman->Interrupt();
    // ...
}

void Shutdown(NodeContext& node)
{
    // ...
    if (node.connman) node.connman->Stop();
    // ...
    node.connman.reset();
    // ...
}
----

The `node` variable refers to the `https://github.com/bitcoin/bitcoin/blob/c7dd9ff71b9c2e62fa7ecfb37ee7a5841ad67ecc/src/node/context.h#L39[struct NodeContext]`. It is a struct that contains references to chain state and connection state. This is used by the init function, RPC, GUI and test code to pass object references around without needing to declare the same variables and parameters repeatedly, or to use globals. The struct is defined in `https://github.com/bitcoin/bitcoin/blob/c7dd9ff71b9c2e62fa7ecfb37ee7a5841ad67ecc/src/node/context.h[src/node/context.h]`.

Before this struct was created, the global variable `g_conman` was used to manage the connection. But using global variables reduces the modularity and flexibility of the program, so the https://github.com/bitcoin/bitcoin/pull/16839[PR #16839] has gotten rid of the some global variables and has made `g_conman` a NodeContext member (now called `https://github.com/bitcoin/bitcoin/blob/c7dd9ff71b9c2e62fa7ecfb37ee7a5841ad67ecc/src/node/context.h#L43[connman]`).

=== Starting The Connections

`CConnman::Start()` initiates all the network process and keeps them running. The first step is creating sockets for listening for incoming connections. By default, the sockets will be binded to 0.0.0.0:8333 (IPv4), [::]:8333 (IPv6) and 127.0.0.1:8334 (as a proxy for onion network). However, the user can define an different address passing it through the `-bind` or `-whitebind` argument when stating the node. This is done by `CConnman::InitBinds()`.

.Difference between `-bind` and `-whitebind`
[NOTE]
===============================
`-whitebind` option which works like `-bind`, except peers connecting to it are whitelisted (allowing a separate listen port for trusted connections). It was implemented in the https://github.com/bitcoin/bitcoin/pull/4378[PR #4378].
===============================

// Bind code
[source,c++]  
----
bool CConnman::Start(CScheduler& scheduler, const Options& connOptions)
{
    Init(connOptions);

    if (fListen && !InitBinds(connOptions.vBinds, connOptions.vWhiteBinds, connOptions.onion_binds)) {
        if (clientInterface) {
            clientInterface->ThreadSafeMessageBox(
                _("Failed to listen on any port. Use -listen=0 if you want this."),
                "", CClientUIInterface::MSG_ERROR);
        }
        return false;
    }
    // ...
}
----

[source,c++]  
----
bool CConnman::InitBinds(...)
{
    // ...
    for (const auto& addrBind : binds) {
        fBound |= Bind(addrBind, (BF_EXPLICIT | BF_REPORT_ERROR), NetPermissionFlags::None);
    }
    for (const auto& addrBind : whiteBinds) {
        fBound |= Bind(addrBind.m_service, (BF_EXPLICIT | BF_REPORT_ERROR), addrBind.m_flags);
    }
    if (binds.empty() && whiteBinds.empty()) {
        struct in_addr inaddr_any;
        inaddr_any.s_addr = htonl(INADDR_ANY);
        struct in6_addr inaddr6_any = IN6ADDR_ANY_INIT;
        fBound |= Bind(CService(inaddr6_any, GetListenPort()), BF_NONE, NetPermissionFlags::None);
        fBound |= Bind(CService(inaddr_any, GetListenPort()), !fBound ? BF_REPORT_ERROR : BF_NONE, NetPermissionFlags::None);
    }
    // ...
}
----

Next, if the user also has specified `-seednode`, an `ADDR_FETCH` connection is created for each seed to retrieve the addresses. +
`CConnman::AddAddrFetch()` adds the seed to `m_addr_fetches` vector. The method `CConnman::ProcessAddrFetch()` gets the first address of the vector and create the `ADDR_FETCH` connection using `CConnman::OpenNetworkConnection(...)`.

`CConnman::ProcessAddrFetch()` is called uninterruptedly in the `CConnman::ThreadOpenConnections()` thread. The method only stops working when `interruptNet` is triggered, which happens when the node is shut down.

`ProcessAddrFetch()` is also once called if the node is started with `connect=<ip>`. The reason is that seeds can also be inserted in  `m_addr_fetches` in `CConnman::ThreadDNSAddressSeed()` if the node is behind a proxy or if the seeder does not support service bit filtering over DNS.

Then, the `CConnman` loads addresses from `peers.dat`. This is done by by `CAddrDB::Read(CAddrMan& addr)`, which deserializes the contents of the file and allocates them to `CAddrMan& addr`. The sole purpose of `CAddrDB` is to write and read the (IP) address database (`peers.dat`).

[source,c++]  
----
// src/net.cpp
bool CConnman::Start(...)
{
    // ...
    CAddrDB adb;
    if (adb.Read(addrman))
        LogPrintf("Loaded %i addresses from peers.dat  %dms\n", addrman.size(), GetTimeMillis() - nStart);
    else {
        addrman.Clear(); // Addrman can be in an inconsistent state after failure, reset it
        LogPrintf("Recreating peers.dat\n");
        DumpAddresses();
    }
    // ...
}

// src/addrdb.cpp
CAddrDB::CAddrDB()
{
    pathAddr = gArgs.GetDataDirNet() / "peers.dat";
}

bool CAddrDB::Write(const CAddrMan& addr)
{
    return SerializeFileDB("peers", pathAddr, addr);
}

bool CAddrDB::Read(CAddrMan& addr)
{
    return DeserializeFileDB(pathAddr, addr);
}
----

Note that `CConnman::addrman` is a reference to `NodeContext::addrman`. Both are the same object. There is only one `CConnman` and one`CAddrman` in the entire application, defined in `NodeContext`.

The next step is loading addresses from `anchors.dat`, which stores the addresses of block-relay connections that have already been made. This is done by `ReadAnchors()` 

`CConnman::m_use_addrman_outgoing` indicates whether the node wants to initiate outbound connections. It will be false only if `-connect` argument is set when starting the node.

[source,c++]  
----
// src/net.cpp
bool CConnman::Start(...)
{
    // ...
    if (m_use_addrman_outgoing) {
        // Load addresses from anchors.dat
        m_anchors = ReadAnchors(gArgs.GetDataDirNet() / ANCHORS_DATABASE_FILENAME);
        if (m_anchors.size() > MAX_BLOCK_RELAY_ONLY_ANCHORS) {
            m_anchors.resize(MAX_BLOCK_RELAY_ONLY_ANCHORS);
        }
        LogPrintf("%i block-relay-only anchors will be tried for connections.\n", m_anchors.size());
    }
    // ...
}
----

Then, semaphores are initialized for limiting connections. `semOutbound` is used to control outgoing connections and `semAddnode` to manual connections. `CSemaphore` constructor takes a counter as parameter, which is the maximum number of connections allowed. The counter is initialized in the constructor. Acquiring the semaphore decreases the counter, and releasing the semaphore increases the counter. This was implemented in the https://github.com/bitcoin/bitcoin/pull/1260[PR #1260].

// max conn

There are three flags to control the network activities:

. `InterruptSocks5` interrupts reading bytes from a proxy. The user can specify a proxy for all outgoing network traffic with `-proxy` argument.

. `interruptNet` signals when network activity should cease. This object is an instance of `CThreadInterrupt`, a helper class for interruptible sleeps. It overloads the () operator, which sets the `flag` field is set to true. In various network threads, there is an infinite loop controlled by this variable. When its value is true, the thread stops. `CThreadInterrupt::reset()` sets it to false again.

. `flagInterruptMsgProc` is a boolean field and it is set to `true` when the node is interrupted. It is only used in `CConnman::ThreadMessageHandler` thread to stop receiving new messages.

These flags were implemented in the https://github.com/bitcoin/bitcoin/pull/9289[PR #9289]. The objective was to allow asynchronous network handling. It was necessary to have more control over the shutdown process in order to deal with asynchronous connecting and sending/receiving data.

There are 3 flags (and not just one) because the things need to be done in sequence. Message processing needs to be terminated before forcing all networking down, otherwise there is the risk of trying to process a node's messages during its destruction. This behavior can be seen in  `CConnman::Interrupt()`.

[source,c++]  
----
void CConnman::Interrupt()
{
    {
        LOCK(mutexMsgProc);
        flagInterruptMsgProc = true;
    }
    condMsgProc.notify_all();

    interruptNet();
    InterruptSocks5(true);

    if (semOutbound) {
        for (int i=0; i<m_max_outbound; i++) {
            semOutbound->post();
        }
    }

    if (semAddnode) {
        for (int i=0; i<nMaxAddnode; i++) {
            semAddnode->post();
        }
    }
}
----

With the semaphores and flags defined, the next step is to  sequentially start all the network threads.

=== ThreadSocketHandler

The first thread started is the `ThreadSocketHandler`. The thread's main code is a loop that runs three functions continuously until interrupted by `interruptNet` flag.

[source,c++]  
----
void CConnman::ThreadSocketHandler()
{
    while (!interruptNet)
    {
        DisconnectNodes();
        NotifyNumConnectionsChanged();
        SocketHandler();
    }
}
----

`CConnman::DisconnectNodes()` first checks if the network is active via the `fNetworkActive` property, which is `true` by default and can be changed by the RPC command `setnetworkactive`, which disables/enables all P2P network activity. If enabled, all connected nodes will have the `CNode::fDisconnect` field changed to true.

`CNode::fDisconnect` is particularly important field. It is used in various parts of the application to disconnect any node that does not comply with the consensus rules.

[source,c++]  
----
void CConnman::DisconnectNodes()
{
    {
        LOCK(cs_vNodes);

        if (!fNetworkActive) {
            // Disconnect any connected nodes
            for (CNode* pnode : vNodes) {
                if (!pnode->fDisconnect) {
                    LogPrint(BCLog::NET, "Network not active, dropping peer=%d\n", pnode->GetId());
                    pnode->fDisconnect = true;
                }
            }
        }
        // ...
    }
}
----

Note that before accessing `vNode`, there is a `LOCK(cs_vNodes)`. +
`std::vector<CNode*> vNodes` is the vector that stores all connected nodes. Its access is protected by the recursive mutex `Note`. +
The recursive_mutex class is a synchronization primitive that can be used to protect shared data from being simultaneously accessed by multiple threads.
`LOCK(cs_vNodes)` locks the mutex. If another thread has already locked the mutex, a call to lock will block execution until the lock is acquired.

Then the peers with `fDisconnect` field set to true will be disconnected. To do it, there are a few steps: The peer is removed from `vNodes` list, , it releases the outbound semaphore grant, closes the socket and the peer is kept in the disconnected pool (`std::list<CNode*> vNodesDisconnected`) until all references to it (`CNode::nRefCount`) are released.

`CNode::CloseSocketDisconnect()` checks that `CNode::hSocket` is different from `INVALID_SOCKET` and if so, calls `close()` function of POSIX operating system API to close the socket.

`INVALID_SOCKET` is defined as `(SOCKET)(~0)` in `src/compat.h`. It is the same way `WinSock2.h` defines this constant. The reason is that Bitcoin Core originally used `WinSock2.h` to manage socket, but in the commit https://github.com/bitcoin/bitcoin/commit/e874738d3de335faacb83d0398cabdff7477bfa0[e874738], this definition has been added so that the application no longer depends on Windows headers.

`SOCKET` is just an alias for `unsigned int`, so `(SOCKET)(~0)` has the value `4294967295` (a.k.a. `UINT_MAX`). +
`4294967295` and `-1` have the same binary representation of `0xFFFFFFFF` or 32 bits all set to `1`. +
The POSIX function used to create socket is `accept()`. And, upon successful completion, it returns non-negative file descriptor (an integer) of the accepted socket. Otherwise, `-1`. +
Therefore, the `(SOCKET) (~0)` has the same binary value that indicates an error in creating the socket.

.POSIX (Portable Operating System Interface) 
[NOTE]
===============================
POSIX (Portable Operating System Interface) is a set of standard operating system interfaces based on the Unix operating system. 
The idea is that a program written to be based on POSIX standards can be easily ported across a large family of Unix derivatives (including, but not limited to, Linux and OSX).
===============================

[source,c++]  
----
void CConnman::DisconnectNodes()
{
    {
        LOCK(cs_vNodes);
        // ...
        std::vector<CNode*> vNodesCopy = vNodes;
        for (CNode* pnode : vNodesCopy)
        {
            if (pnode->fDisconnect)
            {
                // remove from vNodes
                vNodes.erase(remove(vNodes.begin(), vNodes.end(), pnode), vNodes.end());

                // release outbound grant (if any)
                pnode->grantOutbound.Release();

                // close socket and cleanup
                pnode->CloseSocketDisconnect();

                // hold in disconnected pool until all refs are released
                pnode->Release();
                vNodesDisconnected.push_back(pnode);
            }
        }
    }
    // ...
}
----

There is a mechanism for assessing whether a CNode is still in use: the `CNode::nRefCount`. This field is incremented via `CNode::AddRef()` when the peer is created, during socket service and message handling. And `CNode::Release()` decreases it. When there are no more references to this `CNode`, it can be safely disconnected.

When `CNode::nRefCount` is 0, the node can be deleted and removed from the disconnected pool `vNodesDisconnected`.

[source,c++]  
----
void CConnman::DisconnectNodes()
{
    // ...
    {
        // ...
        std::list<CNode*> vNodesDisconnectedCopy = vNodesDisconnected;
        for (CNode* pnode : vNodesDisconnectedCopy)
        {
            if (pnode->GetRefCount() <= 0) {
                vNodesDisconnected.remove(pnode);
                DeleteNode(pnode);
            }
        }
    }
}
----